import streamlit as st
from PIL import Image
import torch
import torchvision.transforms as transforms
from torchvision.datasets import ImageFolder
import json

# === –ù–∞—Å—Ç—Ä–æ–π–∫–∏ ===
IMG_SIZE = (192, 256)

# 1. –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏
# === –§—É–Ω–∫—Ü–∏—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è ===
def resize_and_center(img, size):
    """
    –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –ø—Ä–æ–ø–æ—Ä—Ü–∏–π –∏ –¥–æ–±–∞–≤–ª—è–µ—Ç —á–µ—Ä–Ω—ã–µ –ø–æ–ª—è
    –¥–ª—è —Ü–µ–Ω—Ç—Ä–∏—Ä–æ–≤–∞–Ω–∏—è –æ–±—ä–µ–∫—Ç–∞
    """
    # –°–æ–∑–¥–∞–µ–º –∫–æ–ø–∏—é, —á—Ç–æ–±—ã –Ω–µ –∏–∑–º–µ–Ω—è—Ç—å –æ—Ä–∏–≥–∏–Ω–∞–ª
    img = img.copy()

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ—Ä–∏–µ–Ω—Ç–∞—Ü–∏—é (–∞–ª—å–±–æ–º–Ω–∞—è/–ø–æ—Ä—Ç—Ä–µ—Ç–Ω–∞—è)
    is_landscape = img.width > img.height

    # –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º –ø–æ –±–æ–ª—å—à–µ–π —Å—Ç–æ—Ä–æ–Ω–µ
    if is_landscape:
        new_width = size[0]
        new_height = int(size[0] * img.height / img.width)
    else:
        new_height = size[1]
        new_width = int(size[1] * img.width / img.height)

    # –†–µ—Å–∞–π–∑ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –ø—Ä–æ–ø–æ—Ä—Ü–∏–π
    img = img.resize((new_width, new_height), Image.BILINEAR)

    # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π —Ö–æ–ª—Å—Ç —Å —á–µ—Ä–Ω—ã–º —Ñ–æ–Ω–æ–º
    new_img = Image.new("RGB", size, (0, 0, 0))

    # –¶–µ–Ω—Ç—Ä–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
    left = (size[0] - img.width) // 2
    top = (size[1] - img.height) // 2
    new_img.paste(img, (left, top))

    return new_img


# === –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ ===
transform = transforms.Compose([
    transforms.Lambda(lambda img: resize_and_center(img, IMG_SIZE)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.5] * 3, std=[0.5] * 3)
])


# === –ó–∞–≥—Ä—É–∑–∫–∞ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö ===
def load_metadata():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏—è –∫–ª–∞—Å—Å–æ–≤ –∏ –æ–ø–∏—Å–∞–Ω–∏—è –∏–∑ JSON-—Ñ–∞–π–ª–æ–≤"""
    try:
        with open('class_names.json', 'r', encoding='utf-8') as f:
            class_names = json.load(f)

        with open('class_descriptions.json', 'r', encoding='utf-8') as f:
            class_descriptions = json.load(f)

        return class_names, class_descriptions
    except FileNotFoundError:
        st.error("–û—à–∏–±–∫–∞: —Ñ–∞–π–ª—ã –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω—ã!")
        st.stop()


CLASS_NAMES, CLASS_DESCRIPTIONS = load_metadata()

@st.cache_resource
def load_model():
    model = torch.jit.load("trashnet_mobile.pt", map_location='cpu')
    model.eval()
    return model

model = load_model()

# === –ó–∞–≥–æ–ª–æ–≤–æ–∫ –∏ –æ–ø–∏—Å–∞–Ω–∏–µ ===
st.title("üóëÔ∏è –≠–∫–æ–ü–æ–º–æ—â–Ω–∏–∫: –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–∞ —É—Ç–∏–ª–∏–∑–∞—Ü–∏–∏ –º—É—Å–æ—Ä–∞")

# === –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è ===
st.subheader("üìù –ö–∞–∫ –ø–æ–ª—É—á–∏—Ç—å –ª—É—á—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç?")
with st.expander("–ü–æ–∫–∞–∑–∞—Ç—å —Å–æ–≤–µ—Ç—ã –ø–æ —Å—ä–µ–º–∫–µ"):
    st.markdown("""
    –ß—Ç–æ–±—ã –ø–æ–≤—ã—Å–∏—Ç—å —Ç–æ—á–Ω–æ—Å—Ç—å —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è, —Å–ª–µ–¥—É–π—Ç–µ —ç—Ç–∏–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º:

    - **–ö–æ–Ω—Ç—Ä–∞—Å—Ç–Ω—ã–π —Ñ–æ–Ω**: –°–Ω–∏–º–∞–π—Ç–µ –æ–±—ä–µ–∫—Ç –Ω–∞ –æ–¥–Ω–æ—Ä–æ–¥–Ω–æ–º –∫–æ–Ω—Ç—Ä–∞—Å—Ç–Ω–æ–º —Ñ–æ–Ω–µ
    - **–ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –∫–∞–¥—Ä–∞**: –ú—É—Å–æ—Ä –¥–æ–ª–∂–µ–Ω –∑–∞–Ω–∏–º–∞—Ç—å ‚â•70% –∫–∞–¥—Ä–∞
    - **–û—Å–≤–µ—â–µ–Ω–∏–µ**: –ò–∑–±–µ–≥–∞–π—Ç–µ –±–ª–∏–∫–æ–≤ –∏ —Å–∏–ª—å–Ω—ã—Ö —Ç–µ–Ω–µ–π
    - **–ú–µ–ª–∫–∏–µ –æ–±—ä–µ–∫—Ç—ã**: –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ä–µ–∂–∏–º –º–∞–∫—Ä–æ—Å—ä–µ–º–∫–∏
    - **–û–¥–∏–Ω –æ–±—ä–µ–∫—Ç**: –ù–µ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—Ä—É–π—Ç–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ –æ–±—ä–µ–∫—Ç–æ–≤ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ
    - **–ß–µ—Ç–∫–æ—Å—Ç—å**: –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –æ–±—ä–µ–∫—Ç –≤ —Ñ–æ–∫—É—Å–µ
    - **–£–≥–æ–ª —Å—ä–µ–º–∫–∏**: –°–Ω–∏–º–∞–π—Ç–µ –æ–±—ä–µ–∫—Ç –ø—Ä—è–º–æ —Å–≤–µ—Ä—Ö—É –∏–ª–∏ —Å–±–æ–∫—É –ø–æ–¥ —É–≥–ª–æ–º 90¬∞
    """)

# === –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å ===
uploaded_file = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –º—É—Å–æ—Ä–∞", type=["jpg", "jpeg", "png"])

if uploaded_file:
    image = Image.open(uploaded_file).convert("RGB")
    st.image(image, caption="–ó–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ", use_container_width=True)


    input_tensor = transform(image).unsqueeze(0)

    with torch.no_grad():
        output = model(input_tensor)
        pred_index = output.argmax(1).item()
        pred_class = CLASS_NAMES[pred_index]
        description = CLASS_DESCRIPTIONS.get(pred_class, pred_class)  # –µ—Å–ª–∏ –æ–ø–∏—Å–∞–Ω–∏–µ –Ω–µ—Ç ‚Äî –≤—ã–≤–æ–¥–∏–º –ø—Ä–æ—Å—Ç–æ –º–µ—Ç–∫—É
        probs = torch.softmax(output, dim=1)
        predicted_index = torch.argmax(probs, dim=1).item()
        confidence = probs[0, predicted_index].item()
        st.success(f"üß† –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π –∫–ª–∞—Å—Å: **{description}** (–¥–æ–≤–µ—Ä–∏–µ: {confidence:.2%})")


# === –°–æ—Ü–∏–∞–ª—å–Ω–∞—è –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–Ω–æ—Å—Ç—å –ø—Ä–æ–µ–∫—Ç–∞ ===
st.divider()
st.subheader("‚ôªÔ∏è –û –ø—Ä–æ–µ–∫—Ç–µ")
st.markdown("""
**–≠–∫–æ–ü–æ–º–æ—â–Ω–∏–∫** - —Å–æ—Ü–∏–∞–ª—å–Ω—ã–π –ø—Ä–æ–µ–∫—Ç, —Å–æ–∑–¥–∞–Ω–Ω—ã–π –¥–ª—è –ø–æ–≤—ã—à–µ–Ω–∏—è —ç–∫–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–π —Å–æ–∑–Ω–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∏ —É–ø—Ä–æ—â–µ–Ω–∏—è —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏ –æ—Ç—Ö–æ–¥–æ–≤. 
–ù–∞—à–∞ –º–∏—Å—Å–∏—è - —Å–¥–µ–ª–∞—Ç—å –ø–µ—Ä–µ—Ä–∞–±–æ—Ç–∫—É –º—É—Å–æ—Ä–∞ –¥–æ—Å—Ç—É–ø–Ω–æ–π –∏ –ø–æ–Ω—è—Ç–Ω–æ–π –¥–ª—è –∫–∞–∂–¥–æ–≥–æ.
""")

# –ë–ª–æ–∫ –¥–ª—è –ø–æ–∂–µ—Ä—Ç–≤–æ–≤–∞–Ω–∏–π
st.markdown("### üíö –ü–æ–¥–¥–µ—Ä–∂–∞—Ç—å –ø—Ä–æ–µ–∫—Ç")
col1, col2 = st.columns([1, 2])
with col1:
    st.info("QR-–∫–æ–¥ –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞")
with col2:
    st.markdown("""
    **–†–µ–∫–≤–∏–∑–∏—Ç—ã –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞:**
    - –°–ë–ü: `+7 (XXX) XXX-XX-XX`
    - –ö–∞—Ä—Ç–∞: `XXXX XXXX XXXX XXXX`
    - –ÆMoney: [https://yoomoney.ru/to/41001123456789](https://yoomoney.ru/to/41001123456789)

    *–õ—é–±–∞—è —Å—É–º–º–∞ –ø–æ–º–æ–∂–µ—Ç —Ä–∞–∑–≤–∏—Ç–∏—é –ø—Ä–æ–µ–∫—Ç–∞!*
    """)

# === –ö–æ–Ω—Ç–∞–∫—Ç–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è ===
st.divider()
st.markdown("""
**–ö–æ–Ω—Ç–∞–∫—Ç—ã –¥–ª—è —Å–æ—Ç—Ä—É–¥–Ω–∏—á–µ—Å—Ç–≤–∞:**
- üìß Email: suhih.v@yandex.ru
- üì± Telegram: @VJATCHESLAV87
""")
