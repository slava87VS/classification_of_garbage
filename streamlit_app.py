import streamlit as st
from PIL import Image
import torch
import torchvision.transforms as transforms
from torchvision.datasets import ImageFolder

# === –ù–∞—Å—Ç—Ä–æ–π–∫–∏ ===
IMG_SIZE = (192, 256)

# 1. –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏
transform = transforms.Compose([
    transforms.Resize(IMG_SIZE),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)
])

# DATA_PATH = '../../class_trash/dataset_marker'
# dataset = ImageFolder(root=DATA_PATH, transform=transform)
CLASS_NAMES = ['alu_41', 'c_ldpe_90', 'c_pap_84', 'c_pet', 'c_pp_folg', 'glass_dark', 'glass_transparent', 'green_glass__pap_22', 'hdpe_2__pet_1', 'hdpe_2__pp_5soft__pet_1', 'hdpe_2_soft', 'hdpe_2_solid', 'hdpe_2_solid__pap_20', 'jb_cover', 'jb_cover__glass_dark', 'ldpe_4_color', 'not_defined', 'other_7', 'pap_20', 'pap_21', 'pap_22', 'pet_1', 'pet_1__pap_22', 'pet_1__pap_22__hdpe_2_solid', 'pp_5_folg', 'pp_5_soft', 'pp_5_soft__pet_1', 'pp_5_solid', 'pp_5_solid__c_ldpe_90', 'ps_6_soft', 'ps_6_solid', 'ps_6_solid__pap_22', 'pvc_3', 'pvc_3__ps_6']


# –°–ª–æ–≤–∞—Ä—å —Å –æ–ø–∏—Å–∞–Ω–∏—è–º–∏ –∫–ª–∞—Å—Å–æ–≤
CLASS_DESCRIPTIONS = {
    "alu_41": "–ö–æ–¥ –ø–µ—Ä–µ—Ä–∞–±–æ—Ç–∫–∏ –∞–ª—é–º–∏–Ω–∏—è 41",
    "c_ldpe_90": "–ü–µ—Ä–µ—Ä–∞–±–æ—Ç–∫–∞ LDPE (–Ω–∏–∑–∫–æ—Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–Ω—ã–π –ø–æ–ª–∏—ç—Ç–∏–ª–µ–Ω) 90",
    "c_pap_84": "–ü–µ—Ä–µ—Ä–∞–±–æ—Ç–∫–∞ –±—É–º–∞–≥–∏ 84",
    "c_pet": "–ü–µ—Ä–µ—Ä–∞–±–æ—Ç–∫–∞ PET-–ø–ª–∞—Å—Ç–∏–∫–∞",
    "c_pp_folg": "–ü–µ—Ä–µ—Ä–∞–±–æ—Ç–∫–∞ —Ñ–æ–ª—å–≥–∏ –∏–∑ –ø–æ–ª–∏–ø—Ä–æ–ø–∏–ª–µ–Ω–∞ (PP)",
    "glass_dark": "–ü–µ—Ä–µ—Ä–∞–±–æ—Ç–∫–∞ —Ç—ë–º–Ω–æ–≥–æ —Å—Ç–µ–∫–ª–∞",
    "glass_transparent": "–ü–µ—Ä–µ—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–æ–∑—Ä–∞—á–Ω–æ–≥–æ —Å—Ç–µ–∫–ª–∞",
    "glass_green__pap_22": "–ü–µ—Ä–µ—Ä–∞–±–æ—Ç–∫–∞ –∑–µ–ª—ë–Ω–æ–≥–æ —Å—Ç–µ–∫–ª–∞ —Å –±—É–º–∞–≥–æ–π 22",
    "hdpe_2__pet_1": "–ü–µ—Ä–µ—Ä–∞–±–æ—Ç–∫–∞ HDPE –∏ PET –ø–ª–∞—Å—Ç–∏–∫–∞",
    "hdpe_2__pp_5soft__pet_1": "–ü–µ—Ä–µ—Ä–∞–±–æ—Ç–∫–∞ HDPE, –º—è–≥–∫–æ–≥–æ PP –∏ PET",
    "hdpe_2_soft": "–ü–µ—Ä–µ—Ä–∞–±–æ—Ç–∫–∞ –º—è–≥–∫–æ–≥–æ HDPE –ø–ª–∞—Å—Ç–∏–∫–∞",
    "hdpe_2_solid": "–ü–µ—Ä–µ—Ä–∞–±–æ—Ç–∫–∞ —Ç–≤—ë—Ä–¥–æ–≥–æ HDPE –ø–ª–∞—Å—Ç–∏–∫–∞",
    "hdpe_2_solid__pap_20": "–ü–µ—Ä–µ—Ä–∞–±–æ—Ç–∫–∞ —Ç–≤—ë—Ä–¥–æ–≥–æ HDPE —Å –±—É–º–∞–≥–æ–π 20",
    "jb_cover": "–ü–µ—Ä–µ—Ä–∞–±–æ—Ç–∫–∞ –∫—Ä—ã—à–µ–∫ JB",
    "jb_cover__glass_dark": "–ü–µ—Ä–µ—Ä–∞–±–æ—Ç–∫–∞ –∫—Ä—ã—à–µ–∫ JB –∏ —Ç—ë–º–Ω–æ–≥–æ —Å—Ç–µ–∫–ª–∞",
    "ldpe_4_color": "–ü–µ—Ä–µ—Ä–∞–±–æ—Ç–∫–∞ —Ü–≤–µ—Ç–Ω–æ–≥–æ LDPE 4",
    "not_defined": "–ö–ª–∞—Å—Å –Ω–µ –æ–ø—Ä–µ–¥–µ–ª—ë–Ω",
    "other_7": "–ü—Ä–æ—á–∏–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã 7",
    "pap_20": "–ü–µ—Ä–µ—Ä–∞–±–æ—Ç–∫–∞ –±—É–º–∞–≥–∏ 20",
    "pap_21": "–ü–µ—Ä–µ—Ä–∞–±–æ—Ç–∫–∞ –±—É–º–∞–≥–∏ 21",
    "pap_22": "–ü–µ—Ä–µ—Ä–∞–±–æ—Ç–∫–∞ –±—É–º–∞–≥–∏ 22",
    "pet_1": "–ü–µ—Ä–µ—Ä–∞–±–æ—Ç–∫–∞ PET –ø–ª–∞—Å—Ç–∏–∫–∞ 1",
    "pet_1__pap_22": "–ü–µ—Ä–µ—Ä–∞–±–æ—Ç–∫–∞ PET —Å –±—É–º–∞–≥–æ–π 22",
    "pet_1__pap_22__hdpe_2_solid": "–ü–µ—Ä–µ—Ä–∞–±–æ—Ç–∫–∞ PET, –±—É–º–∞–≥–∏ 22 –∏ —Ç–≤—ë—Ä–¥–æ–≥–æ HDPE",
    "pp_5_folg": "–ü–µ—Ä–µ—Ä–∞–±–æ—Ç–∫–∞ —Ñ–æ–ª—å–≥–∏ –∏–∑ PP 5",
    "pp_5_soft": "–ü–µ—Ä–µ—Ä–∞–±–æ—Ç–∫–∞ –º—è–≥–∫–æ–≥–æ PP 5",
    "pp_5_soft__pet_1": "–ü–µ—Ä–µ—Ä–∞–±–æ—Ç–∫–∞ –º—è–≥–∫–æ–≥–æ PP 5 –∏ PET",
    "pp_5_solid": "–ü–µ—Ä–µ—Ä–∞–±–æ—Ç–∫–∞ —Ç–≤—ë—Ä–¥–æ–≥–æ PP 5",
    "pp_5_solid__c_ldpe_90": "–ü–µ—Ä–µ—Ä–∞–±–æ—Ç–∫–∞ —Ç–≤—ë—Ä–¥–æ–≥–æ PP 5 –∏ LDPE 90",
    "ps_6_soft": "–ü–µ—Ä–µ—Ä–∞–±–æ—Ç–∫–∞ –º—è–≥–∫–æ–≥–æ PS 6",
    "ps_6_solid": "–ü–µ—Ä–µ—Ä–∞–±–æ—Ç–∫–∞ —Ç–≤—ë—Ä–¥–æ–≥–æ PS 6",
    "ps_6_solid__pap_22": "–ü–µ—Ä–µ—Ä–∞–±–æ—Ç–∫–∞ —Ç–≤—ë—Ä–¥–æ–≥–æ PS 6 –∏ –±—É–º–∞–≥–∏ 22",
    "pvc_3": "–ü–µ—Ä–µ—Ä–∞–±–æ—Ç–∫–∞ PVC 3",
    "pvc_3__ps_6": "–ü–µ—Ä–µ—Ä–∞–±–æ—Ç–∫–∞ PVC 3 –∏ PS 6",
}

@st.cache_resource
def load_model():
    model = torch.jit.load("trashnet_mobile.pt", map_location='cpu')
    model.eval()
    return model

model = load_model()

# === –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å ===
st.title("üóëÔ∏è –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –º—É—Å–æ—Ä–∞ –ø–æ —Ñ–æ—Ç–æ")
uploaded_file = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –º—É—Å–æ—Ä–∞", type=["jpg", "jpeg", "png"])

if uploaded_file:
    image = Image.open(uploaded_file).convert("RGB")
    st.image(image, caption="–ó–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ", use_container_width=True)


    input_tensor = transform(image).unsqueeze(0)

    with torch.no_grad():
        output = model(input_tensor)
        pred_index = output.argmax(1).item()
        pred_class = CLASS_NAMES[pred_index]
        description = CLASS_DESCRIPTIONS.get(pred_class, pred_class)  # –µ—Å–ª–∏ –æ–ø–∏—Å–∞–Ω–∏–µ –Ω–µ—Ç ‚Äî –≤—ã–≤–æ–¥–∏–º –ø—Ä–æ—Å—Ç–æ –º–µ—Ç–∫—É
        st.success(f"üß† –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π –∫–ª–∞—Å—Å: **{description}**")
